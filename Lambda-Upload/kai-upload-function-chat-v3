import boto3
import json
import openai
from openai import OpenAI
from datetime import datetime

# -------------------------------
# ğŸ”‘ Secrets + Clients
# -------------------------------
def get_openai_key():
    secret_name = "openai/api-key"
    client = boto3.client("secretsmanager")
    response = client.get_secret_value(SecretId=secret_name)
    return json.loads(response["SecretString"])["OPENAI_API_KEY"]

openai.api_key = get_openai_key()
s3 = boto3.client("s3")
ddb = boto3.client("dynamodb")

# -------------------------------
# ğŸ§  GPT Summariser
# -------------------------------
def call_gpt_extract(message, original_name="Unknown File"):
    system_prompt = """
    You are a text parser that extracts structured information about uploaded files.
    Always return valid JSON with:
      - gpt_title
      - gpt_tags (list)
      - gpt_summary
    """

    try:
        client = OpenAI(api_key=openai.api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message},
            ],
            temperature=0.2,
            max_tokens=200,
        )
        result_text = response.choices[0].message.content
        result_json = json.loads(result_text)

        if not result_json.get("gpt_title") or not result_json.get("gpt_summary"):
            raise ValueError("GPT returned incomplete data.")

        return result_json

    except Exception as e:
        print(f"âš ï¸ GPT Error: {e}")
        return {
            "gpt_title": f"Auto-summary: {original_name}",
            "gpt_tags": ["fallback"],
            "gpt_summary": f"GPT failed or timed out. Using file name instead. ({e})",
        }

# -------------------------------
# ğŸ’¾ DDB + S3 Write
# -------------------------------
def process_and_save(bucket, key, meta):
    table_name = "kai-assistant-data"
    message = meta.get("message", "")
    user = meta.get("user", "unknown")
    upload_id = meta.get("upload_id", key)
    original_name = meta.get("original_name", key.split("/")[-1])
    timestamp = meta.get("timestamp", "unknown")

    if not message:
        raise Exception("Missing 'message' metadata â€” cannot process file.")

    # ğŸ§  1ï¸âƒ£ GPT Analysis (with fallback)
    gpt_result = call_gpt_extract(message, original_name)
    if not isinstance(gpt_result, dict):
        raise Exception("GPT returned non-dict result â€” invalid format.")

    # ğŸ’¾ 2ï¸âƒ£ DynamoDB Write (with S3 link)
    s3_link = f"https://{bucket}.s3.eu-west-2.amazonaws.com/{key}"

    item = {
        "user_id": {"S": user},
        "file_id": {"S": upload_id},
        "original_name": {"S": original_name},
        "message": {"S": message},
        "tab": {"S": meta.get("tab", "chat")},
        "timestamp": {"S": timestamp},
        "status": {"S": "processed"},
        "source": {"S": "lambda-gpt-processor"},
        "s3_path": {"S": f"s3://{bucket}/{key}"},
        "s3_link": {"S": s3_link},  # âœ… NEW â€” clickable web link
        "gpt_title": {"S": gpt_result.get("gpt_title", "Untitled")},
        "gpt_tags": {"S": json.dumps(gpt_result.get("gpt_tags", []))},
        "gpt_summary": {"S": gpt_result.get("gpt_summary", "")},
        "gpt_result_raw": {"S": json.dumps(gpt_result)},
    }

    try:
        ddb.put_item(TableName=table_name, Item=item)
        print(f"âœ… DynamoDB write successful for {key}")
        print(f"ğŸ”— Public link stored: {s3_link}")
    except Exception as e:
        print(f"âŒ DynamoDB Write Error: {e}")
        raise


    # ğŸ§© 2ï¸âƒ£.5ï¸âƒ£ Update S3 metadata to mark as processed
    try:
        new_meta = meta.copy()
        new_meta["status"] = "processed"
        new_meta["processed_at"] = datetime.utcnow().isoformat()

        head = s3.head_object(Bucket=bucket, Key=key)
        content_type = head.get("ContentType", "application/octet-stream")

        # ğŸ§  Smart rule: inline for readable types only
        viewable_types = ["image/", "text/", "application/pdf"]
        if any(content_type.startswith(t) for t in viewable_types):
            content_disposition = "inline"
        else:
            content_disposition = "attachment"

        s3.copy_object(
            Bucket=bucket,
            Key=key,
            CopySource={"Bucket": bucket, "Key": key},
            Metadata=new_meta,
            MetadataDirective="REPLACE",
            ContentType=content_type,
            ContentDisposition=content_disposition,
            CacheControl="no-cache",
        )

        print(
            f"ğŸ” S3 metadata updated to '{content_disposition}' for {key} ({content_type})"
        )

    except Exception as e:
        print(f"âš ï¸ Metadata update failed (non-critical): {e}")

    # ğŸ·ï¸ 3ï¸âƒ£ Tag S3 object
    try:
        s3.put_object_tagging(
            Bucket=bucket,
            Key=key,
            Tagging={
                "TagSet": [
                    {"Key": "Status", "Value": "processed"},
                    {"Key": "Tab", "Value": meta.get("tab", "chat")},
                    {
                        "Key": "GPT_Tags",
                        "Value": "-".join(
                            [t.replace(" ", "_") for t in gpt_result.get("gpt_tags", [])]
                        )[:128],
                    },
                ]
            },
        )
        print(f"ğŸ·ï¸ S3 tagging complete for {key}")
    except Exception as e:
        print(f"âš ï¸ Tagging Error (non-critical): {e}")

    return {
        "statusCode": 200,
        "body": json.dumps(
            {
                "route": meta.get("tab", "chat"),
                "file": key,
                "gpt_result": gpt_result,
            }
        ),
    }

# -------------------------------
# ğŸ§© Route Handlers
# -------------------------------
def handle_chat(bucket, key, meta):
    print("ğŸ’¬ Handling chat upload...")
    return process_and_save(bucket, key, meta)

def handle_taxclaim(bucket, key, meta):
    print("ğŸ’¼ Handling tax claim upload...")
    return process_and_save(bucket, key, meta)

# -------------------------------
# ğŸš€ Main Handler
# -------------------------------
def lambda_handler(event, context):
    print("ğŸ“¥ Incoming event:", json.dumps(event, indent=2))

    def extract_s3_details(record):
        try:
            if record.get("eventSource") == "aws:s3":
                return record["s3"]["bucket"]["name"], record["s3"]["object"]["key"]
            if record.get("EventSource") == "aws:sns":
                sns_message = json.loads(record["Sns"]["Message"])
                inner = sns_message["Records"][0]
                return inner["s3"]["bucket"]["name"], inner["s3"]["object"]["key"]
            if record.get("eventSource") == "aws:sqs":
                body = json.loads(record["body"])
                inner = body["Records"][0]
                return inner["s3"]["bucket"]["name"], inner["s3"]["object"]["key"]
        except Exception as e:
            print(f"âš ï¸ Failed to extract S3 details: {e}")
        return None, None

    if "Records" not in event:
        print("âš™ï¸ Manual test route")
        return {
            "statusCode": 200,
            "body": json.dumps({"message": "Manual mode â€” no Records found."}),
        }

    for record in event["Records"]:
        bucket, key = extract_s3_details(record)
        if not bucket or not key:
            print("âš ï¸ No S3 details found, skipping record.")
            continue

        print(f"ğŸ“¦ Processing file: s3://{bucket}/{key}")

        try:
            head = s3.head_object(Bucket=bucket, Key=key)
            meta = head.get("Metadata", {})
            route = meta.get("tab", "chat")

            print(f"ğŸ§¾ Metadata: {json.dumps(meta, indent=2)}")
            print(f"ğŸ”€ Route selected: {route}")

            if route == "taxclaim":
                result = handle_taxclaim(bucket, key, meta)
            else:
                result = handle_chat(bucket, key, meta)

            print(f"âœ… Processing complete for {key}")
            return result

        except Exception as e:
            print(f"ğŸ”¥ Lambda failed for {key}: {e}")
            raise

    return {"statusCode": 200, "body": json.dumps({"message": "All records processed."})}
